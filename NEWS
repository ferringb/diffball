0.6.5
* Bug fixes.  bufferless reconstruction should work without issue now.
* Further code cleanup in preparation for attempting largefile (>2gb) support.
* convert_delta got a new feature; no longer limited to specifying only one patch for conversion.  You can now specify
  < 255 patches, and the patches are collapsed down into a single patch.  Doesn't do any optimization, but at this point 
  there really isn't any optimization done on the command lists.  Expect that sometime prior to 0.7

0.6.2 and under
* Reconstruction via multiple patches is now supported for all supported patch formats- no limitations on mixing formats also.
  I'd suspect a bug or two linger, but not many (been threw a fair amount of testing).
  
  No temps files used, each patch's command are merged into a single buffer in memory, rather then using intermediate files.

  Only limitation is number of registered dcb srcs; 256 is the current max.
  For switching/bdiff/bdelta/gdiff/xdelta, 256 patches are allowed.
  For bdiff, dependant on the version, figure 128- bsdiff is broken down into multiple bz2'd segments, so for reconstructing
  from a bsdiff patch patcher must maintain 2 decompressors into the file.

* Reading from compressed (gzip and bzip2, currently) patches/files is now supported, and pretty well tested.
  *NOTE* this is mainly for patcher, and convert_delta.  Using compressed srcs for differ/diffball isn't sane (due to issues 
  w/ seeking detailed below).

* During reconstruction, it's now possible to reorder commands so that file(s) used to reconstruct the target, are read linearly- 
  in general usage, this isn't needed unless src(s) are compressed, or multiple overlay-format patches are being applied 
  (ex: 2 bsdiff patches being applied).
  
  When a source is compressed, this makes a world of difference- gzip/bzip2 cseek implementations either decompress their 
  way forward to the desired location, or destruct the decompressor, re-init it, and read from the beginning of the cfile to the 
  desired position. 

  That behaviour sucks, but is something of the norm.  zlib's gzseek is implemented this way for instance.
  The commands are reordered such that copies from a src are in sequential order- writes to the reconstructed file are random.
  
  This isn't as quick as I'd like it to be, but its worst case is *much* saner then for dealing w/ seeking in compressed srcs.
  I would suspect it's performance could be tuned a bit, but currently it is better then the alternative.

* Default behaviour for applying single patches is now to _not_ read in the entire patch commands; now it just executes them as 
  it encounters them, unless A) applying multiple patches, B) decompressing files, C) reorder for read seq write random is in effect.
  Decreases memory usage nicely, and doesn't affect performance.

* One Half Pass Correcting alg implementation has been rewritten- basically the same, just minus an extra set of buffers.
  Quicker overall, and some long standing corner cases accessing beyond the buffers has been fixed.
  
* Lots of adjustments to CommandBuffer, and cfile.  Mostly expanding functionality, although there have been optimizations fixes.
  Introduced a DCB_registered_src struct- this is an abstraction to allow for overlay commands, and standard commands.
  Basically, things are saner/cleaner.  That, and a package wide reduction of intermediate buffers.
